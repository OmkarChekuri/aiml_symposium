{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell imports the packages that you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path\n",
    "import collections\n",
    "import numpy\n",
    "import netCDF4\n",
    "from gewittergefahr.gg_utils import error_checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell defines the constants that you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BATCHES_PER_DIRECTORY = 1000\n",
    "BATCH_NUMBER_REGEX = '[0-9][0-9][0-9][0-9][0-9][0-9][0-9]'\n",
    "\n",
    "TEMPERATURE_NAME = 'temperature_kelvins'\n",
    "HEIGHT_NAME = 'height_m_asl'\n",
    "SPECIFIC_HUMIDITY_NAME = 'specific_humidity_kg_kg01'\n",
    "WET_BULB_THETA_NAME = 'wet_bulb_potential_temperature_kelvins'\n",
    "U_WIND_GRID_RELATIVE_NAME = 'u_wind_grid_relative_m_s01'\n",
    "V_WIND_GRID_RELATIVE_NAME = 'v_wind_grid_relative_m_s01'\n",
    "\n",
    "VALID_PREDICTOR_NAMES = [\n",
    "    TEMPERATURE_NAME, HEIGHT_NAME, SPECIFIC_HUMIDITY_NAME, WET_BULB_THETA_NAME,\n",
    "    U_WIND_GRID_RELATIVE_NAME, V_WIND_GRID_RELATIVE_NAME\n",
    "]\n",
    "\n",
    "PREDICTOR_MATRIX_KEY = 'predictor_matrix'\n",
    "TARGET_MATRIX_KEY = 'target_matrix'\n",
    "TARGET_TIMES_KEY = 'target_times_unix_sec'\n",
    "ROW_INDICES_KEY = 'row_indices'\n",
    "COLUMN_INDICES_KEY = 'column_indices'\n",
    "PREDICTOR_NAMES_KEY = 'narr_predictor_names'\n",
    "NARR_MASK_KEY = 'narr_mask_matrix'\n",
    "PRESSURE_LEVEL_KEY = 'pressure_level_mb'\n",
    "DILATION_DISTANCE_KEY = 'dilation_distance_metres'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell defines private methods that you will need.  Since this is a notebook and not a proper Python package, there is really no distinction between public and private methods.  However, I have used the syntax for private methods (underscore at the beginning of the method name), to emphasize that these are low-level helper methods and you shouldn't worry about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_predictor_name(field_name):\n",
    "    \"\"\"Ensures that name of model field is recognized.\n",
    "\n",
    "    :param field_name: Field name in GewitterGefahr format (not the original\n",
    "        NetCDF format).\n",
    "    :raises: ValueError: if field name is unrecognized.\n",
    "    \"\"\"\n",
    "\n",
    "    error_checking.assert_is_string(field_name)\n",
    "\n",
    "    if field_name not in VALID_PREDICTOR_NAMES:\n",
    "        error_string = (\n",
    "            '\\n\\n' + str(VALID_PREDICTOR_NAMES) +\n",
    "            '\\n\\nValid field names (listed above) do not include \"' +\n",
    "            field_name + '\".')\n",
    "        raise ValueError(error_string)\n",
    "\n",
    "\n",
    "def _floor_to_nearest(input_value, rounding_base):\n",
    "    \"\"\"Rounds numbers *down* to nearest x, where x is a positive real number.\n",
    "\n",
    "    :param input_value: Either numpy array of real numbers or scalar real\n",
    "        number.\n",
    "    :param rounding_base: Numbers will be rounded *down* to this base.\n",
    "    :return: output_value: Same as input_value, except rounded.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(input_value, collections.Iterable):\n",
    "        error_checking.assert_is_real_numpy_array(input_value)\n",
    "    else:\n",
    "        error_checking.assert_is_real_number(input_value)\n",
    "\n",
    "    error_checking.assert_is_greater(rounding_base, 0)\n",
    "    return rounding_base * numpy.floor(input_value / rounding_base)\n",
    "\n",
    "\n",
    "def _file_name_to_batch_number(downsized_3d_file_name):\n",
    "    \"\"\"Parses file name for batch number.\n",
    "\n",
    "    :param downsized_3d_file_name: See doc for `find_downsized_3d_example_file`.\n",
    "    :return: batch_number: Integer.\n",
    "    :raises: ValueError: if batch number cannot be parsed from file name.\n",
    "    \"\"\"\n",
    "\n",
    "    pathless_file_name = os.path.split(downsized_3d_file_name)[-1]\n",
    "    extensionless_file_name = os.path.splitext(pathless_file_name)[0]\n",
    "    return int(extensionless_file_name.split('downsized_3d_examples_batch')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method shrinks the dimensions of a training examples.  The original examples (stored in the files) are 65 rows (latitudes) x 65 columns (longitudes).  Shrinking the grids makes them easier to work with.  The grid dimensions must always be odd numbers, which is why the input arguments are num_half_rows and num_half_columns, rather than num_rows and num_columns.  This ensures that there is exactly one center grid cell, which is the grid cell whose label (no front, warm front, or cold front) we are trying to predict.  For example, if you want to shrink the grids to 33 x 33, make num_half_rows=16 and num_half_columns=16.  The grids will be cropped around the center, so the center grid cell will remain the same.  It's just the number of surrounding grid cells that may shrink."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrease_example_size(predictor_matrix, num_half_rows, num_half_columns):\n",
    "    \"\"\"Decreases the grid size for each example.\n",
    "\n",
    "    M = original number of rows per example\n",
    "    N = original number of columns per example\n",
    "    m = new number of rows per example\n",
    "    n = new number of columns per example\n",
    "\n",
    "    :param predictor_matrix: E-by-M-by-N-by-C numpy array of predictor images.\n",
    "    :param num_half_rows: Determines number of rows returned for each example.\n",
    "        Examples will be cropped so that the center of the original image is the\n",
    "        center of the new image.  If `num_half_rows`, examples will not be\n",
    "        cropped.\n",
    "    :param num_half_columns: Same but for columns.\n",
    "    :return: predictor_matrix: E-by-m-by-n-by-C numpy array of predictor images.\n",
    "    \"\"\"\n",
    "\n",
    "    if num_half_rows is not None:\n",
    "        error_checking.assert_is_integer(num_half_rows)\n",
    "        error_checking.assert_is_greater(num_half_rows, 0)\n",
    "\n",
    "        center_row_index = int(\n",
    "            numpy.floor(float(predictor_matrix.shape[1]) / 2)\n",
    "        )\n",
    "        first_row_index = center_row_index - num_half_rows\n",
    "        last_row_index = center_row_index + num_half_rows\n",
    "        predictor_matrix = predictor_matrix[\n",
    "            :, first_row_index:(last_row_index + 1), ...\n",
    "        ]\n",
    "\n",
    "    if num_half_columns is not None:\n",
    "        error_checking.assert_is_integer(num_half_columns)\n",
    "        error_checking.assert_is_greater(num_half_columns, 0)\n",
    "\n",
    "        center_column_index = int(\n",
    "            numpy.floor(float(predictor_matrix.shape[2]) / 2)\n",
    "        )\n",
    "        first_column_index = center_column_index - num_half_columns\n",
    "        last_column_index = center_column_index + num_half_columns\n",
    "        predictor_matrix = predictor_matrix[\n",
    "            :, :, first_column_index:(last_column_index + 1), ...\n",
    "        ]\n",
    "\n",
    "    return predictor_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method locates a file with training examples.  On average each file contains 512 training examples: 256 NF examples (with no front at the center grid cell), 128 WF examples (warm front at the center grid cell), and 128 CF examples (cold front at the center grid cell).  The original class distribution is much more skewed (98.95% of examples are NF), which makes the deep-learning model nearly insensitive to the minority classes (WF and CF), which leads to the predicted probabilities of WF and CF always being very low.  Balancing the training data fixes the problem.  Unfortunately it causes the DL models to overpredict the WF and CF classes, but this can be mitigated by post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_downsized_3d_example_file(\n",
    "        top_directory_name, batch_number, raise_error_if_missing=True):\n",
    "    \"\"\"Finds file with downsized 3-D examples.\n",
    "\n",
    "    :param top_directory_name: Name of top-level directory for files with\n",
    "        downsized 3-D examples.\n",
    "    :param batch_number: Batch number (integer).\n",
    "    :param raise_error_if_missing: Boolean flag.  If file is missing and\n",
    "        `raise_error_if_missing = True`, this method will error out.\n",
    "    :return: downsized_3d_file_name: Path to file with downsized 3-D examples.\n",
    "        If file is missing and `raise_error_if_missing = False`, this is the\n",
    "        *expected* path.\n",
    "    :raises: ValueError: if file is missing and `raise_error_if_missing = True`.\n",
    "    \"\"\"\n",
    "\n",
    "    error_checking.assert_is_string(top_directory_name)\n",
    "    error_checking.assert_is_boolean(raise_error_if_missing)\n",
    "\n",
    "    error_checking.assert_is_integer(batch_number)\n",
    "    error_checking.assert_is_geq(batch_number, 0)\n",
    "\n",
    "    first_batch_number = int(_floor_to_nearest(\n",
    "        batch_number, NUM_BATCHES_PER_DIRECTORY))\n",
    "    last_batch_number = first_batch_number + NUM_BATCHES_PER_DIRECTORY - 1\n",
    "\n",
    "    downsized_3d_file_name = (\n",
    "        '{0:s}/batches{1:07d}-{2:07d}/downsized_3d_examples_batch{3:07d}.nc'\n",
    "    ).format(top_directory_name, first_batch_number, last_batch_number,\n",
    "             batch_number)\n",
    "\n",
    "    if raise_error_if_missing and not os.path.isfile(downsized_3d_file_name):\n",
    "        error_string = 'Cannot find file.  Expected at: \"{0:s}\"'.format(\n",
    "            downsized_3d_file_name)\n",
    "        raise ValueError(error_string)\n",
    "\n",
    "    return downsized_3d_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method locates many files with training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_downsized_3d_example_files(\n",
    "        top_directory_name, first_batch_number, last_batch_number):\n",
    "    \"\"\"Finds many files with downsized 3-D examples.\n",
    "\n",
    "    :param top_directory_name: See doc for `find_downsized_3d_example_file`.\n",
    "    :param first_batch_number: First batch number.\n",
    "    :param last_batch_number: Last batch number.\n",
    "    :return: downsized_3d_file_names: 1-D list of file paths.\n",
    "    :raises: ValueError: if no files are found.\n",
    "    \"\"\"\n",
    "\n",
    "    error_checking.assert_is_string(top_directory_name)\n",
    "\n",
    "    error_checking.assert_is_integer(first_batch_number)\n",
    "    error_checking.assert_is_integer(last_batch_number)\n",
    "    error_checking.assert_is_geq(first_batch_number, 0)\n",
    "    error_checking.assert_is_geq(last_batch_number, first_batch_number)\n",
    "\n",
    "    downsized_3d_file_pattern = (\n",
    "        '{0:s}/batches{1:s}-{1:s}/downsized_3d_examples_batch{1:s}.nc'\n",
    "    ).format(top_directory_name, BATCH_NUMBER_REGEX)\n",
    "\n",
    "    downsized_3d_file_names = glob.glob(downsized_3d_file_pattern)\n",
    "    if len(downsized_3d_file_names) == 0:\n",
    "        error_string = 'Cannot find any files with the pattern: \"{0:s}\"'.format(\n",
    "            downsized_3d_file_pattern)\n",
    "        raise ValueError(error_string)\n",
    "\n",
    "    batch_numbers = numpy.array(\n",
    "        [_file_name_to_batch_number(f) for f in downsized_3d_file_names],\n",
    "        dtype=int)\n",
    "    good_indices = numpy.where(numpy.logical_and(\n",
    "        batch_numbers >= first_batch_number,\n",
    "        batch_numbers <= last_batch_number\n",
    "    ))[0]\n",
    "\n",
    "    if len(good_indices) == 0:\n",
    "        error_string = (\n",
    "            'Cannot find any files with batch number in [{0:d}, {1:d}].'\n",
    "        ).format(first_batch_number, last_batch_number)\n",
    "        raise ValueError(error_string)\n",
    "\n",
    "    return [downsized_3d_file_names[i] for i in good_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method reads a file with training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_downsized_3d_examples(\n",
    "        netcdf_file_name, metadata_only=False, predictor_names_to_keep=None,\n",
    "        num_half_rows_to_keep=None, num_half_columns_to_keep=None):\n",
    "    \"\"\"Reads downsized 3-D examples from NetCDF file.\n",
    "\n",
    "    :param netcdf_file_name: Path to input file.\n",
    "    :param metadata_only: Boolean flag.  If True, will return only metadata\n",
    "        (everything except predictor and target matrices).\n",
    "    :param predictor_names_to_keep: 1-D list with names of predictor variables\n",
    "        to keep (each name must be accepted by `_check_predictor_name`).  If\n",
    "        `predictor_names_to_keep is None`, all predictors in the file will be\n",
    "        returned.\n",
    "    :param num_half_rows_to_keep: [used iff `metadata_only == False`]\n",
    "        Determines number of rows to keep for each example.  Examples will be\n",
    "        cropped so that the center of the original image is the center of the\n",
    "        new image.  If `num_half_rows_to_keep is None`, examples will not be\n",
    "        cropped.\n",
    "    :param num_half_columns_to_keep: [used iff `metadata_only == False`]\n",
    "        Same but for columns.\n",
    "    :return: example_dict: Dictionary with the following keys.\n",
    "    example_dict['predictor_matrix']: See doc for\n",
    "        `prep_downsized_3d_examples_to_write`.\n",
    "    example_dict['target_matrix']: Same.\n",
    "    example_dict['target_times_unix_sec']: Same.\n",
    "    example_dict['row_indices']: Same.\n",
    "    example_dict['column_indices']: Same.\n",
    "    example_dict['predictor_names_to_keep']: See doc for\n",
    "        `write_downsized_3d_examples`.\n",
    "    example_dict['pressure_level_mb']: Same.\n",
    "    example_dict['dilation_distance_metres']: Same.\n",
    "    example_dict['narr_mask_matrix']: Same.\n",
    "    \"\"\"\n",
    "\n",
    "    error_checking.assert_is_boolean(metadata_only)\n",
    "    if predictor_names_to_keep is not None:\n",
    "        error_checking.assert_is_numpy_array(\n",
    "            numpy.array(predictor_names_to_keep), num_dimensions=1)\n",
    "        for this_name in predictor_names_to_keep:\n",
    "            _check_predictor_name(this_name)\n",
    "\n",
    "    netcdf_dataset = netCDF4.Dataset(netcdf_file_name)\n",
    "\n",
    "    narr_predictor_names = netCDF4.chartostring(\n",
    "        netcdf_dataset.variables[PREDICTOR_NAMES_KEY][:])\n",
    "    narr_predictor_names = [str(s) for s in narr_predictor_names]\n",
    "    if predictor_names_to_keep is None:\n",
    "        predictor_names_to_keep = narr_predictor_names + []\n",
    "\n",
    "    target_times_unix_sec = numpy.array(\n",
    "        netcdf_dataset.variables[TARGET_TIMES_KEY][:], dtype=int)\n",
    "    row_indices = numpy.array(\n",
    "        netcdf_dataset.variables[ROW_INDICES_KEY][:], dtype=int)\n",
    "    column_indices = numpy.array(\n",
    "        netcdf_dataset.variables[COLUMN_INDICES_KEY][:], dtype=int)\n",
    "\n",
    "    if not metadata_only:\n",
    "        predictor_matrix = numpy.array(\n",
    "            netcdf_dataset.variables[PREDICTOR_MATRIX_KEY][:])\n",
    "        target_matrix = numpy.array(\n",
    "            netcdf_dataset.variables[TARGET_MATRIX_KEY][:])\n",
    "\n",
    "        these_indices = numpy.array(\n",
    "            [narr_predictor_names.index(p) for p in predictor_names_to_keep],\n",
    "            dtype=int)\n",
    "        predictor_matrix = predictor_matrix[..., these_indices]\n",
    "        predictor_matrix = decrease_example_size(\n",
    "            predictor_matrix=predictor_matrix,\n",
    "            num_half_rows=num_half_rows_to_keep,\n",
    "            num_half_columns=num_half_columns_to_keep)\n",
    "\n",
    "    example_dict = {\n",
    "        TARGET_TIMES_KEY: target_times_unix_sec,\n",
    "        ROW_INDICES_KEY: row_indices,\n",
    "        COLUMN_INDICES_KEY: column_indices,\n",
    "        PREDICTOR_NAMES_KEY: predictor_names_to_keep,\n",
    "        PRESSURE_LEVEL_KEY: int(getattr(netcdf_dataset, PRESSURE_LEVEL_KEY)),\n",
    "        DILATION_DISTANCE_KEY: getattr(netcdf_dataset, DILATION_DISTANCE_KEY),\n",
    "        NARR_MASK_KEY:\n",
    "            numpy.array(netcdf_dataset.variables[NARR_MASK_KEY][:], dtype=int)\n",
    "    }\n",
    "\n",
    "    if metadata_only:\n",
    "        netcdf_dataset.close()\n",
    "        return example_dict\n",
    "\n",
    "    example_dict.update({\n",
    "        PREDICTOR_MATRIX_KEY: predictor_matrix.astype('float32'),\n",
    "        TARGET_MATRIX_KEY: target_matrix.astype('float64')\n",
    "    })\n",
    "\n",
    "    netcdf_dataset.close()\n",
    "    return example_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
